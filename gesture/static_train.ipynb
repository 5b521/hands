{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify to fix the structure of the proj\n",
    "# import lib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "def settle_seed(seed= 42):\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.manual_seed(seed) \n",
    "#   torch.cuda.manual_seed(seed) \n",
    "#   torch.cuda.manual_seed_all(seed) \n",
    "#   torch.backends.cudnn.deterministic = True \n",
    "#   torch.backends.cudnn.benchmark = False \n",
    "#   torch.backends.cudnn.enabled = True \n",
    "settle_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data and number of classes in data\n",
    "dataset = config.train_dataset_csv_path\n",
    "model_save_path = config.train_model_output_path\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting dataloader\n",
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "class KeyPointDataset(Dataset):\n",
    "    def __init__(self,X_dataset, y_dataset):\n",
    "        self.X = X_dataset\n",
    "        self.y = y_dataset\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.X[item],dtype= torch.float32), torch.tensor(self.y[item],dtype=torch.long) \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "train_dataset = KeyPointDataset(X_dataset, y_dataset)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset,[3200, 800])\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True )\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size= 32, shuffle= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and parameters of training\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(21*2, 128),\n",
    "    nn.ReLU(),\n",
    "    # nn.Sigmoid(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    # nn.Sigmoid(),\n",
    "    nn.Linear(32, NUM_CLASSES),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001,weight_decay= 1e-4)\n",
    "epochs = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainging: epoch:0,step:100,mean_loss:1.19310,mean_acc:0.63031\n",
      "Trainging: epoch:1,step:200,mean_loss:0.87765,mean_acc:0.90625\n",
      "Trainging: epoch:2,step:300,mean_loss:0.84239,mean_acc:0.91781\n",
      "Trainging: epoch:3,step:400,mean_loss:0.82738,mean_acc:0.92563\n",
      "Validing: step:500,mean_loss:0.77394,mean_acc:0.97500\n",
      "Trainging: epoch:4,step:500,mean_loss:0.81329,mean_acc:0.94000\n",
      "Trainging: epoch:5,step:600,mean_loss:0.81033,mean_acc:0.94000\n",
      "Trainging: epoch:6,step:700,mean_loss:0.81111,mean_acc:0.93875\n",
      "Trainging: epoch:7,step:800,mean_loss:0.80462,mean_acc:0.94437\n",
      "Trainging: epoch:8,step:900,mean_loss:0.79890,mean_acc:0.94719\n",
      "Validing: step:1000,mean_loss:0.76817,mean_acc:0.97875\n",
      "Trainging: epoch:9,step:1000,mean_loss:0.80083,mean_acc:0.94781\n",
      "Trainging: epoch:10,step:1100,mean_loss:0.79973,mean_acc:0.94281\n",
      "Trainging: epoch:11,step:1200,mean_loss:0.79672,mean_acc:0.95094\n",
      "Trainging: epoch:12,step:1300,mean_loss:0.79435,mean_acc:0.95281\n",
      "Trainging: epoch:13,step:1400,mean_loss:0.80020,mean_acc:0.94219\n",
      "Validing: step:1500,mean_loss:0.76828,mean_acc:0.97750\n",
      "Trainging: epoch:14,step:1500,mean_loss:0.79256,mean_acc:0.95531\n",
      "Trainging: epoch:15,step:1600,mean_loss:0.79567,mean_acc:0.94906\n",
      "Trainging: epoch:16,step:1700,mean_loss:0.79364,mean_acc:0.95344\n",
      "Trainging: epoch:17,step:1800,mean_loss:0.79180,mean_acc:0.95375\n",
      "Trainging: epoch:18,step:1900,mean_loss:0.79513,mean_acc:0.94937\n",
      "Validing: step:2000,mean_loss:0.76547,mean_acc:0.97875\n",
      "Trainging: epoch:19,step:2000,mean_loss:0.79235,mean_acc:0.95187\n"
     ]
    }
   ],
   "source": [
    "def evaluate(step):\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = [] \n",
    "    valid_acc = [] \n",
    "    for eval_batch in valid_data_loader:\n",
    "        X, label = eval_batch\n",
    "        X = X.to(device)\n",
    "        label = label.to(device) \n",
    "        pred = model.forward(X) \n",
    "        loss = criterion(pred,label) \n",
    "        acc = sum(torch.argmax(pred,dim = 1) == label) / len(label) \n",
    "        valid_loss.append(loss) \n",
    "        valid_acc.append(acc)\n",
    "        # tb.save_value('loss', 'loss', loss.item(), step)\n",
    "        # tb.save_value('acc', 'acc', acc.item(), step)\n",
    "        # valid_writer.add_scalar('loss',loss.item(),step) \n",
    "        # valid_writer.add_scalar('acc',acc.item(),step) \n",
    "    valid_loss = sum(valid_loss) / len(valid_loss) \n",
    "    valid_acc = sum(valid_acc) / len(valid_acc) \n",
    "    return valid_loss,valid_acc\n",
    "def train():\n",
    "    step = 0 \n",
    "    model.to(device) \n",
    "    min_loss = float('inf') \n",
    "    for epoch in range(epochs):\n",
    "        model.train() \n",
    "        train_loss = [] \n",
    "        train_acc = []\n",
    "        for batch in train_data_loader:\n",
    "            optimizer.zero_grad() \n",
    "            X, label = batch \n",
    "            # X = X.unsqueeze(1) # in channels \n",
    "            X = X.to(device) \n",
    "            label = label.to(device)\n",
    "            pred = model.forward(X) \n",
    "            loss = criterion(pred,label) \n",
    "            acc = sum(torch.argmax(pred, dim = 1) == label) / len(label) \n",
    "            train_loss.append(loss) \n",
    "            train_acc.append(acc)\n",
    "            # tb.save_value('Train Loss', 'train_loss', loss.item(), step)\n",
    "            # tb.save_value('Train acc', 'train_acc', acc.item(), step)\n",
    "            # train_writer.add_scalar('loss',loss.item(),step) \n",
    "            # train_writer.add_scalar('acc',acc.item(),step) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            if step % 500 == 0:\n",
    "                valid_loss,valid_acc = evaluate(step)\n",
    "                print('Validing: step:%d,mean_loss:%.5f,mean_acc:%.5f' % ( step,valid_loss,valid_acc)) \n",
    "                if valid_loss < min_loss:\n",
    "                    min_loss = valid_loss \n",
    "                    torch.save(model.state_dict(), model_save_path) \n",
    "        mean_loss = sum(train_loss) / len(train_loss) \n",
    "        mean_acc = sum(train_acc) / len(train_acc) \n",
    "        print('Trainging: epoch:%d,step:%d,mean_loss:%.5f,mean_acc:%.5f' % ( epoch,step,mean_loss,mean_acc))\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hands_dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a3e29cce8ff42baa8442838b73f2d6321b0b29868c7c185067930f9d75918e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
